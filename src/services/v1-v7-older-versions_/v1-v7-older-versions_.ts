// This file was generated by liblab | https://liblab.com/

import { z } from 'zod';
import { BaseService } from '../base-service';
import { ContentType, HttpResponse } from '../../http';
import { RequestConfig } from '../../http/types';
import { RequestBuilder } from '../../http/transport/request-builder';
import {
  ScoreAWordOrSentence1Request,
  scoreAWordOrSentence1RequestRequest,
} from './models/score-a-word-or-sentence1-request';
import {
  ScoreAWordOrSentence1OkResponse,
  scoreAWordOrSentence1OkResponseResponse,
} from './models/score-a-word-or-sentence1-ok-response';
import {
  ScoreAPhonemeList1Params,
  ScoreAWordOrSentence1Params,
  TranscribeScore1Params,
  ValidateText1Params,
} from './request-params';
import { ScoreAPhonemeList1Request, scoreAPhonemeList1RequestRequest } from './models/score-a-phoneme-list1-request';
import {
  ScoreAPhonemeList1OkResponse,
  scoreAPhonemeList1OkResponseResponse,
} from './models/score-a-phoneme-list1-ok-response';
import { ValidateText1OkResponse, validateText1OkResponseResponse } from './models/validate-text1-ok-response';
import { TranscribeScore1Request, transcribeScore1RequestRequest } from './models/transcribe-score1-request';
import { TranscribeScore1OkResponse, transcribeScore1OkResponseResponse } from './models/transcribe-score1-ok-response';

export class V1V7OlderVersions_Service extends BaseService {
  /**
 * **In this example we score pronunciation of a word or sentence**
Scoring pronunciation provides a quality score for the speaker's pronunciation for the entire utterance and for each word, syllable, phoneme. This allows overall activity scoring and pin-pointed feedback on pronunciation mistakes.

In this request JSON result includes the following fields:

Field | Description
:------:|:-----:
quality_score | An overall pronunciation score for the the entire utterance on a scale of 0 to 100. See [guide](https://docs.speechace.com/#b41375b3-a9e6-48f0-aa92-a9a1a0aed116) for detail on score rubric.
syllable_score_list[] | a list of syllables in each word in the word_score_list[], each with it's own quality_score
word_score_list[] | a list of words in the utterance, each with it's own quality_score
syllable_score_list[] | a list of syllables in each word in the word_score_list[], each with it's own quality_score
phone_score_list[] | a list of phonemes in each word in the word_score_list[], each with it's own quality_score
extent[] | start and end boundaries of a syllable or phoneme in units of 10 msec.
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are "en-us" (US English) and "en-gb" (UK English).

en-gb requires setting v0.1 in url path. i.e. `https://api.speechace.co/api/scoring/text/v0.1/json?`
 * @param {string} [userId] - A unique anonymized identifier for the end-user who spoke the audio. 

Structure this field to include as much info as possible to aid in reporting and analytics.

For example: **user_id=XYZ-ABC-99001** where:
 
* XYZ is an id for your Product or App
* ABC is an id for the customer/site/account
* 99001 is an id for the end-user

Ensure user_id is unique and anonymized containing **no personally identifiable information**.
 * @param {string} [__] - 
 * @returns {Promise<HttpResponse<ScoreAWordOrSentence1OkResponse>>} Score Pronunciation - Word Example / Score Pronunciation - Sentence Example / Score a Multiple Choice Text Example / Score Fluency example / Score Lexical Stress & Intonation / Score Vocabulary & Grammar
 */
  async scoreAWordOrSentence1(
    body: ScoreAWordOrSentence1Request,
    params?: ScoreAWordOrSentence1Params,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ScoreAWordOrSentence1OkResponse>> {
    const request = new RequestBuilder<ScoreAWordOrSentence1OkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/text/v0.5/json')
      .setRequestSchema(scoreAWordOrSentence1RequestRequest)
      .setResponseSchema(scoreAWordOrSentence1OkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('dialect', params?.dialect)
      .addQueryParam('user_id', params?.userId)
      .addQueryParam('', params?.__)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ScoreAWordOrSentence1OkResponse>(request);
  }

  /**
 * **In this example we score the term:**
"gotcha" /g/ao1/ch/ah0

Since **gotcha** is an american vernacular and not a valid dictionary word we use the phoneme list API to score it. 

The phoneme list uses a different url endpoint and expects the list of phonemes in [Arpabet notation](https://en.wikipedia.org/wiki/Arpabet).

Note that we specify phoneme stress as 0,1,2 per Arpabet notation. This API allows you to score any word or sentence that can phonetically expressed in Arpabet.

**Copy the example code and be sure to:**

1. Add your Speechace API key
2. Add a valid file path in the **user_audio_file** parameter. *For example in curl the you would add something like @/tmp/gotcha_16k.wav*

You can download a sample *gotcha_16k.wav* file [here](https://s3-us-west-2.amazonaws.com/speechace-public/sample-audio/gotcha_16k.wav).
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [userId] - A unique anonymized identifier for the end-user who spoke the audio. 

Structure this field to include as much info as possible to aid in reporting and analytics.

For example: **user_id=XYZ-ABC-99001** where:
 
* XYZ is an id for your Product or App
* ABC is an id for the customer/site/account
* 99001 is an id for the end-user

Ensure user_id is unique and anonymized containing **no personally identifiable information**.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are "en-us" (US English) and "en-gb" (UK English).

en-gb requires setting v0.1 in url path. i.e. `https://api.speechace.co/api/scoring/text/v0.1/json?`
 * @returns {Promise<HttpResponse<ScoreAPhonemeList1OkResponse>>} Score a Phoneme list Example
 */
  async scoreAPhonemeList1(
    body: ScoreAPhonemeList1Request,
    params?: ScoreAPhonemeList1Params,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ScoreAPhonemeList1OkResponse>> {
    const request = new RequestBuilder<ScoreAPhonemeList1OkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/phone_list/v0.5/json')
      .setRequestSchema(scoreAPhonemeList1RequestRequest)
      .setResponseSchema(scoreAPhonemeList1OkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('user_id', params?.userId)
      .addQueryParam('dialect', params?.dialect)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ScoreAPhonemeList1OkResponse>(request);
  }

  /**
 * In this example we validate whether all the words in the text exist in the Speechace lexicon. This API allows you to quickly check whether authored content will be able to be scored with Speechace. This is useful to use at the time of text authoring to avoid errors later on.
Out of lexicon terms can be reported to support@speechace.com for inclusion. Or you can see the phoneme list API as an alternative.

**Copy the example code and be sure to:**

1. Add your Speechace API key
2. Replace text with the text you wish to validate.
3. Set the dialect parameter to the dialect you will use when scoring. If you are not sure which dialect will be used then validate once using each available dialect.
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [text] - A sentence or sequence of words to validate.
 * @param {string} [dialect] - The dialect to use for validation. Default is "en-us". Supported values are "en-us" (US English) and "en-gb" (UK English).
 * @returns {Promise<HttpResponse<ValidateText1OkResponse>>} Validate text with Speechace lexicon
 */
  async validateText1(
    body: any,
    params?: ValidateText1Params,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ValidateText1OkResponse>> {
    const request = new RequestBuilder<ValidateText1OkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/validating/text/v0.5/json')
      .setRequestSchema(z.any())
      .setResponseSchema(validateText1OkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('text', params?.text)
      .addQueryParam('dialect', params?.dialect)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ValidateText1OkResponse>(request);
  }

  /**
 * **In this example we transcribe a free speaking audio and score the response providing an estimated IELTS score for each of the following aspects:**
*   Fluency
*   Pronunciation
*   Grammar
*   Vocabulary
*   Coherence
    

The API accepts the user audio and a relevance context as inputs. The relevance context is typically a question prompt provided to the user. The relevance context is used to provide a relevance assessment of whether the users response is relevant or not. Irrelevant answers have the overall IELTS score automatically set to zero.

In this request JSON result includes the following fields:

| Field | Description |
| --- | --- |
| transcript | The speech-to-text transcript of what the user has said. |
| relevance.class | Boolean. Whether the user response is relevant to the relevance context passed to the API. |
| ielts_estimate | an estimate of the IELTS Speaking Fluency of the speaker |
| ielts_subscore.vocab | an estimate of the IELTS Vocabulary level of the speaker's response |
| ielts_subscore.grammar | an estimate of the IELTS Grammar level of the speaker's response |
| ielts_subscore.coherence | an estimate of the IELTS Coherence level of the speaker's response |
| quality_score | An overall pronunciation score for the the utterance on a scale of 0 to 100. See [guide](https://docs.speechace.com/#b41375b3-a9e6-48f0-aa92-a9a1a0aed116) for detail on score rubric. |
| duration | total length of speech in seconds |
| articulation | total length of articulation (speech minus pauses, hesitations and non-speech events such as laughter). Excludes beginning silence on very first segment and ending silence on very last segment. |
| speech_rate | speaking rate in syllables per second. |
| articulation_rate | articulation rate in syllables per second. |
| syllable_count | Count of syllables in this segmtent |
| word_count | Count of words in this segment |
| correct_syllable_count | Count of correctly spoken syllables in this segment |
| correct_word_count | Count of correctly spoken words in this segment |
| syllable_correct_per_minute | correct_syllable_count / duration in mins |
| word_correct_per_minute | correct_word_count / duration in mins |
| all_pause_count | count of all pauses (filled and unfilled) which are longer than the minimum pause threshold |
| all_pause_duration | total duration of all pauses (filled and unfilled) in seconds |
| all_pause_list\[\] | a list of all the pauses with the begin/end markers for each in extents of 10 msecs |
| mean_length_run | mean length of run in syllables between pauses |
| max_length_run | max length of run in syllables between pauses |
| segment_metrics_list\[\] | A list of segments within the overall text/audio with the IELTS scores, subscrores, and fluency metrics for each segment. |
| syllable_score_list\[\] | a list of syllables in each word in the word_score_list\[\], each with it's own quality_score |
| word_score_list\[\] | a list of words in the utterance, each with it's own quality_score |
| syllable_score_list\[\] | a list of syllables in each word in the word_score_list\[\], each with it's own quality_score |
| phone_score_list\[\] | a list of phonemes in each word in the word_score_list\[\], each with it's own quality_score |
| extent\[\] | start and end boundaries of a syllable or phoneme in units of 10 msec. |
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are "en-us" (US English) and "en-gb" (UK English).
 * @param {string} [userId] - A unique anonymized identifier for the end-user who spoke the audio. 
Structure this field to include as much info as possible to aid in reporting and analytics.
For example: **user_id=XYZ-ABC-99001** where:
 
* XYZ is an id for your Product or App
* ABC is an id for the customer/site/account
* 99001 is an id for the end-user
Ensure user_id is unique and anonymized containing **no personally identifiable information**.
 * @returns {Promise<HttpResponse<TranscribeScore1OkResponse>>} Transcribe & Score / Score Relevance
 */
  async transcribeScore1(
    body: TranscribeScore1Request,
    params?: TranscribeScore1Params,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<TranscribeScore1OkResponse>> {
    const request = new RequestBuilder<TranscribeScore1OkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/speech/v0.5/json')
      .setRequestSchema(transcribeScore1RequestRequest)
      .setResponseSchema(transcribeScore1OkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('dialect', params?.dialect)
      .addQueryParam('user_id', params?.userId)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<TranscribeScore1OkResponse>(request);
  }
}
