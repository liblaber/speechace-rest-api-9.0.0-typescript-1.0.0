// This file was generated by liblab | https://liblab.com/

import { z } from 'zod';
import { BaseService } from '../base-service';
import { ContentType, HttpResponse } from '../../http';
import { RequestConfig } from '../../http/types';
import { RequestBuilder } from '../../http/transport/request-builder';
import {
  ScoreAWordOrSentenceRequest,
  scoreAWordOrSentenceRequestRequest,
} from './models/score-a-word-or-sentence-request';
import {
  ScoreAWordOrSentenceOkResponse,
  scoreAWordOrSentenceOkResponseResponse,
} from './models/score-a-word-or-sentence-ok-response';
import {
  ScoreAPhonemeListParams,
  ScoreAWordOrSentenceParams,
  ScoreTaskParams,
  TranscribeScoreParams,
  ValidateTextParams,
} from './request-params';
import { ScoreAPhonemeListRequest, scoreAPhonemeListRequestRequest } from './models/score-a-phoneme-list-request';
import {
  ScoreAPhonemeListOkResponse,
  scoreAPhonemeListOkResponseResponse,
} from './models/score-a-phoneme-list-ok-response';
import { ValidateTextOkResponse, validateTextOkResponseResponse } from './models/validate-text-ok-response';
import { ScoreTaskRequest, scoreTaskRequestRequest } from './models/score-task-request';
import { TranscribeScoreRequest, transcribeScoreRequestRequest } from './models/transcribe-score-request';
import { TranscribeScoreOkResponse, transcribeScoreOkResponseResponse } from './models/transcribe-score-ok-response';

export class V9Latest_Service extends BaseService {
  /**
 * **In this example we score pronunciation of a word or sentence**
The overall score is returned as a `speechace_score` on a scale of 0 to 100.

In addition, the API returns a `quality_score` on a scale of 0 to 100 for each word, syllable, and phoneme in the utterance which allows pin-pointed feedback on pronunciation mistakes made by the speaker.

### Overall Score

The API result contains the following score field under the `text_score` node:

| **Field** | **Description** |
| --- | --- |
| speecahce_score.pronunciation | An overall pronunciation score for the the entire utterance on a scale of 0 to 100. See [guide](https://docs.speechace.com/#b41375b3-a9e6-48f0-aa92-a9a1a0aed116) for detail on score rubric. |

### **Feedback Subscores**

In addition the API returns the following lists of elements and subscores.

| Field | Description |
| --- | --- |
| word_score_list\[\] | a list of words in the utterance, each with it's own quality_score |
| syllable_score_list\[\] | a list of syllables in each word in the word_score_list\[\], each with it's own quality_score |
| phone_score_list\[\] | a list of phonemes in each word in the word_score_list\[\], each with it's own quality_score |

Each element has its own `quality_score` (see [guide](https://docs.speechace.com/#b41375b3-a9e6-48f0-aa92-a9a1a0aed116)), its `extent` information marking its begin and end in time (see [guide](https://docs.speechace.com/#84c3936d-d51f-464e-8157-9ffc701ade96)) and additional fields.

For example each element in `phone_score_list[]` identifies the expected `phone` in [Arpabet phonetic notation](https://docs.speechace.com/#bbde2f96-dedf-41f9-803d-b40801a969bb) and the actual `sound_most_like` phone based on the speaker's attempt. It also includes the `word_extent` for that phone to enable [mapping to its corresponding letters](https://docs.speechace.com/#3381d375-76bd-4a3a-bcd0-af029e752484) in the word.  
This enables Applications to visually demonstrate pronunciation errors to the speaker.

``` json
"word_score_list":[
  {
    "word": "Some",
    "quality_score": 100,
    "phone_score_list": [
      {
        "phone": "s",
        "stress_level": null,
        "extent": [10,27],
        "quality_score": 99.05882352941177,
        "sound_most_like": "s"
      },
      {
        "phone": "ah",
        "stress_level": 1,
        "extent": [27,36],
        "quality_score": 100,
        "stress_score": 100,
        "sound_most_like": "ah"
      },
      ...
    }
]

 ```
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are "en-us" (US English) and "en-gb" (UK English).
 * @param {string} [userId] - Optional: A unique anonymized identifier for the end-user who spoke the audio.
 * @param {string} [__] - 
 * @returns {Promise<HttpResponse<ScoreAWordOrSentenceOkResponse>>} Score a word / Score a sentence / Score Letter Names (A B C D E F G) / Score Letter sounds (b BAT) / Example - fr-fr / Example - fr-ca / Example - es-es / Score a Multiple Choice Text Example / Score MC with markup language / Example - read (present) vs. read (past) / Example: 007 (Double-O Seven) / Example: Multiple Choice with Markup / Example: Letter to Phoneme mapping / Example - Correct response / Example - Incomplete response / Beta - Score Lexical Stress & Intonation / Example - fr-ca / Example - es-mx / Example - es-es
 */
  async scoreAWordOrSentence(
    body: ScoreAWordOrSentenceRequest,
    params?: ScoreAWordOrSentenceParams,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ScoreAWordOrSentenceOkResponse>> {
    const request = new RequestBuilder<ScoreAWordOrSentenceOkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/text/v9/json')
      .setRequestSchema(scoreAWordOrSentenceRequestRequest)
      .setResponseSchema(scoreAWordOrSentenceOkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('dialect', params?.dialect)
      .addQueryParam('user_id', params?.userId)
      .addQueryParam('', params?.__)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ScoreAWordOrSentenceOkResponse>(request);
  }

  /**
 * **In this example we score the term:**
"gotcha" /g/ao1/ch/ah0

Since **gotcha** is an american vernacular and not a valid dictionary word we use the phoneme list API to score it.

The phoneme list uses a different url endpoint and expects the list of phonemes in [Arpabet notation](https://en.wikipedia.org/wiki/Arpabet).

Note that we specify phoneme stress as 0,1,2 per Arpabet notation. This API allows you to score any word or sentence that can phonetically expressed in Arpabet.
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [userId] - Optional: A unique anonymized identifier for the end-user who spoke the audio.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are "en-us" (US English) and "en-gb" (UK English).
 * @returns {Promise<HttpResponse<ScoreAPhonemeListOkResponse>>} Score a Phoneme list example
 */
  async scoreAPhonemeList(
    body: ScoreAPhonemeListRequest,
    params?: ScoreAPhonemeListParams,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ScoreAPhonemeListOkResponse>> {
    const request = new RequestBuilder<ScoreAPhonemeListOkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/phone_list/v9/json')
      .setRequestSchema(scoreAPhonemeListRequestRequest)
      .setResponseSchema(scoreAPhonemeListOkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('user_id', params?.userId)
      .addQueryParam('dialect', params?.dialect)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ScoreAPhonemeListOkResponse>(request);
  }

  /**
 * In this example we validate whether all the words in the text exist in the Speechace lexicon. This API allows you to quickly check whether authored content will be able to be scored with Speechace. This is useful to use at the time of text authoring to avoid errors later on.
Out of lexicon terms can be reported to [support@speechace.com](mailto:support@speechace.com) for inclusion. Or you can see the phoneme list API as an alternative.

You may also opt let Speechace API [automatically handle unknown words](https://docs.speechace.com/#2f59fc09-d3ef-410c-b9e8-ee91dddc0eec) by finding the most likely phonetic mapping for the term.
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [text] - A sentence or sequence of words to validate.
 * @param {string} [dialect] - The dialect to use for validation. Default is "en-us". Supported values are "en-us" (US English) and "en-gb" (UK English).
 * @returns {Promise<HttpResponse<ValidateTextOkResponse>>} Validate Text with unknown words / Validate Text with known words
 */
  async validateText(
    body: any,
    params?: ValidateTextParams,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<ValidateTextOkResponse>> {
    const request = new RequestBuilder<ValidateTextOkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/validating/text/v9/json')
      .setRequestSchema(z.any())
      .setResponseSchema(validateTextOkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('text', params?.text)
      .addQueryParam('dialect', params?.dialect)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<ValidateTextOkResponse>(request);
  }

  /**
 * This section contains a full description of the Score Task request type. In the subsequent sections you can find specific request examples for the following task types:
- describe-image
- retell-lecture
- answer-question
 * @param {string} [key] - API key issued by Speechace
 * @param {string} [taskType] - The task_type to score. Supported types are: describe-image, retell-lecture, answer-question.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are: en-us, en-gb, fr-fr, fr-ca, es-es, es-mx.
 * @returns {Promise<HttpResponse<any>>}  / DI example with audio / DI example with text / RL example with audio / RL example with text / AQ example with audio / AQ example with audio and no speech score / AQ example with text
 */
  async scoreTask(
    body: ScoreTaskRequest,
    params?: ScoreTaskParams,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<undefined>> {
    const request = new RequestBuilder<undefined>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/task/v9/json')
      .setRequestSchema(scoreTaskRequestRequest)
      .setResponseSchema(z.undefined())
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('task_type', params?.taskType)
      .addQueryParam('dialect', params?.dialect)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<undefined>(request);
  }

  /**
 * **In this example we transcribe a free speaking audio and score the response providing an estimated IELTS and CEFR score for each of the following aspects:**
- Fluency
    
- Pronunciation
    
- Grammar
    
- Vocabulary
    
- Coherence
    

The API accepts the user audio and a `relevance_context` as inputs. The `relevance_context` is typically a question prompt provided to the user and is used to provide a relevance assessment of whether the user's response is relevant or not. Irrelevant answers have the overall IELTS score automatically set to zero and a warning is returned in the `score_issue_list[]` in the API result.

### Overall Scores

The overall score is returned in 5 formats. See the [Scoring Rubrics Guide](https://docs.speechace.com/#1a63edfe-1c4d-4c49-a694-95ee9638ebbe) to understand how the different formats map to each other:

- A `speechace_score` on a scale of 0 to 100
    
- An `ielts_score` on a standard IELTS scale of 0 to 9.0
    
- A `pte_score` on a standard PTE scale or 10 to 90
    
- A `cefr_score` on a standard scale of A0 to C2
    
- A `toeic_score` on a standard scale of 0 to 200
    

In addition, the API returns segment (sentence) level scores to provide feedback on the speaker's weaknesses on the whole and at specific segments within the passage.

The API result contains the following score fields under the `speech_score` node:

| **Field** | **Description** |
| --- | --- |
| transcript | The speech-to-text transcript of what the user has said. |
| speechace_score | An overall score on a scale of 0 to 100, in addition to subscores for: Fluency, Pronunciation, Grammar, Vocabulary, Coherence. |
| ielts_score | An overall score on an IELTS scale of 0 to 9.0, in addition to subscores for: Fluency, Pronunciation, Grammar, Vocabulary, Coherence. |
| pte_score | An overall score on a PTE scale of 10 to 90, in addition to subscores for: Fluency, Pronunciation, Grammar, Vocabulary, Coherence. |
| cefr_score | An overall score on CEFR scale of A0 to C2, in addition to subscores for: Fluency, Pronunciation, Grammar, Vocabulary, Coherence. |
| toeic_score | An overall score on an TOEIC scale of 0 to 200, in addition to subscores for: Fluency, Pronunciation, Grammar, Vocabulary, Coherence. |
| relevance.class | TRUE or FALSE indicating whether the response was relevant given the `relevance_context` passed as input to the API. |

The following example snippet from the API results demonstrates the overall scores:

``` json
{
  "status": "success",
  "speech_score":
  {
    "transcript": "But the residents have felt the strain, they to launched a healthy streets program, opening up, select streets to just walking and cycling. Now, this action proved valuable in helping residents life and broaden the benefit of their tax dollars. That typically pay to serve cars. New designs were implemented on South Congress. The iconic Main Street of Texas, Inn, Downtown Austin, the stretch of road has changed character overtime evolve e with advances in technology Civic priorities or public preferences with City council's Direction. This stretch of road now has just two fewer Lanes of car traffic. A third of the street space was given over to people bicycling and rolling on scooters. Taking them off the busy sidewalks better suited for dining under the oak trees and give them increased comfort and safety.",
    "relevance": { "class": "TRUE" },
    "ielts_score":
    {
        "pronunciation": 8.5,
        "fluency": 9,
        "grammar": 8.5,
        "coherence": 9,
        "vocab": 9,
        "overall": 9
    },
    "pte_score":
    {
        "pronunciation": 86,
        "fluency": 87,
        "grammar": 86,
        "coherence": 90,
        "vocab": 89,
        "overall": 87
    },
    "speechace_score": 
    {
        "pronunciation": 97,
        "fluency": 98,
        "grammar": 97,
        "coherence": 100,
        "vocab": 99,
        "overall": 98
    },
    "toeic_score":
    {
        "pronunciation": 190,
        "fluency": 200,
        "grammar": 190,
        "coherence": 200,
        "vocab": 200,
        "overall": 200
    },
    "cefr_score": 
    {
        "pronunciation": "C2",
        "fluency": "C2",
        "grammar": "C2",
        "coherence": "C2",
        "vocab": "C2",
        "overall": "C2"
    }
     ...
  }
}

 ```

### Feedback Metrics

In addition, the API returns the following feedback nodes:

| **Node** | **Description** |
| --- | --- |
| fluency | This node contains fluency metrics and subscores for the overall utterance and for each segment (sentence) within the utterance. |
| word_score_list\[\] | This node contains pronunciation scores and metrics for each word, syllable, and phoneme within the utterance. |
| grammar | This node contains grammar metrics, errors and feedback for the overall utterance. |
| vocab | This node contains vocabulary metrics, errors and feedback for the overall utterance. |
| coherence | This node contains coherence metrics, errors and feedback for the overall utterance. |
 * @param {string} [key] - API key issued by Speechace.
 * @param {string} [dialect] - The dialect to use for scoring. Supported values are:
en-us (US English)
en-gb (UK English)
fr-fr (French France)
fr-ca (French Canada)
es-es (Spanish Spain)
es-mx (Spanish Mexico)
 * @param {string} [userId] - Optional: A unique anonymized identifier for the end-user who spoke the audio. 
 * @returns {Promise<HttpResponse<TranscribeScoreOkResponse>>} Transcribe & Score / Example - Relevant Response / Example - response_relevance_false / Example - response_too_similar / Get Grammar, Vocab, Coherence feedback metrics
 */
  async transcribeScore(
    body: TranscribeScoreRequest,
    params?: TranscribeScoreParams,
    requestConfig?: RequestConfig,
  ): Promise<HttpResponse<TranscribeScoreOkResponse>> {
    const request = new RequestBuilder<TranscribeScoreOkResponse>()
      .setConfig(this.config)
      .setBaseUrl(this.config)
      .setMethod('POST')
      .setPath('/api/scoring/speech/v9/json')
      .setRequestSchema(transcribeScoreRequestRequest)
      .setResponseSchema(transcribeScoreOkResponseResponse)
      .setRequestContentType(ContentType.MultipartFormData)
      .setResponseContentType(ContentType.Json)
      .setRetryAttempts(this.config, requestConfig)
      .setRetryDelayMs(this.config, requestConfig)
      .setResponseValidation(this.config, requestConfig)
      .addQueryParam('key', params?.key)
      .addQueryParam('dialect', params?.dialect)
      .addQueryParam('user_id', params?.userId)
      .addHeaderParam('Content-Type', 'multipart/form-data')
      .addBody(body)
      .build();
    return this.client.call<TranscribeScoreOkResponse>(request);
  }
}
